{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_this(s,title=''):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    import pylab\n",
    "    s = s.squeeze()\n",
    "    if s.ndim ==1:\n",
    "        pylab.plot(s)\n",
    "    else:\n",
    "        pylab.imshow(s,aspect='auto')\n",
    "        pylab.title(title)\n",
    "    pylab.show()\n",
    "\n",
    "import torch \n",
    "def calculate_scaling_factor(clean_audio, noise_audio, target_snr):\n",
    "    \"\"\"Calculate the scaling factor to adjust noise to the target SNR level.\"\"\"\n",
    "    target_snr = float(target_snr)\n",
    "    clean_power = torch.mean(clean_audio**2)\n",
    "    noise_power = torch.mean(noise_audio**2)\n",
    "    desired_noise_power = clean_power / (10 ** (target_snr / 10))\n",
    "    scaling_factor = torch.sqrt(desired_noise_power / noise_power)\n",
    "    return scaling_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import re\n",
    "# import shutil\n",
    "# import random\n",
    "# from collections import defaultdict\n",
    "# from pathlib import Path\n",
    "\n",
    "# def parse_reader_id(filename):\n",
    "#     \"\"\"Extract reader ID from filename like: book_0000_chp_009_reader_84372_2.wav\"\"\"\n",
    "#     match = re.search(r\"reader_(\\d+)_\", filename)\n",
    "#     return match.group(1) if match else None\n",
    "\n",
    "# def organize_clips_from_flat_dir(src_dir, dest_dir, num_speakers=10, clips_per_speaker=10, seed=42):\n",
    "#     random.seed(seed)\n",
    "#     src_dir = Path(src_dir)\n",
    "#     dest_dir = Path(dest_dir)\n",
    "#     clean_wav_dir = dest_dir / \"clean_wav\"\n",
    "#     clean_train_dir = dest_dir / \"clean_train\"\n",
    "#     clean_wav_dir.mkdir(parents=True, exist_ok=True)\n",
    "#     clean_train_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     # Step 1: Group files by speaker (reader)\n",
    "#     speaker_to_files = defaultdict(list)\n",
    "#     for file in src_dir.glob(\"*.wav\"):\n",
    "#         reader_id = parse_reader_id(file.name)\n",
    "#         if reader_id:\n",
    "#             speaker_to_files[reader_id].append(file)\n",
    "\n",
    "#     # Step 2: Filter and randomly select speakers\n",
    "#     eligible_speakers = [s for s, files in speaker_to_files.items() if len(files) >= clips_per_speaker]\n",
    "#     selected_speakers = random.sample(eligible_speakers, min(num_speakers, len(eligible_speakers)))\n",
    "\n",
    "#     for reader_id in selected_speakers:\n",
    "#         files = random.sample(speaker_to_files[reader_id], clips_per_speaker)\n",
    "#         main_clip = files[0]\n",
    "#         support_clips = files[1:]\n",
    "\n",
    "#         # Copy main clip to clean_wav/\n",
    "#         shutil.copy(main_clip, clean_wav_dir / main_clip.name)\n",
    "\n",
    "#         # Copy other 9 to clean_train/<main_clip_stem>/\n",
    "#         support_dir = clean_train_dir / main_clip.stem\n",
    "#         support_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         for clip in support_clips:\n",
    "#             shutil.copy(clip, support_dir / clip.name)\n",
    "\n",
    "#         print(f\"Processed speaker {reader_id}: main={main_clip.name}, train={len(support_clips)} clips\")\n",
    "\n",
    "# # Example usage\n",
    "# organize_clips_from_flat_dir(\n",
    "#     src_dir=\"/data/ephraim/datasets/DNS-Challenge_old/datasets/clean\",\n",
    "#     dest_dir=\"/data/ephraim/datasets/known_noise/undiff_exps2/exp_p5lib_net2b/\"\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: speaker 03714 as fileid_0\n",
      "Saved: speaker 09440 as fileid_1\n",
      "Saved: speaker 11377 as fileid_2\n",
      "Saved: speaker 04199 as fileid_3\n",
      "Saved: speaker 11207 as fileid_4\n",
      "Saved: speaker 06475 as fileid_5\n",
      "Saved: speaker 04433 as fileid_6\n",
      "Saved: speaker 00123 as fileid_7\n",
      "Saved: speaker 06271 as fileid_8\n",
      "Saved: speaker 04278 as fileid_9\n",
      "Saved: speaker 07893 as fileid_10\n",
      "Saved: speaker 08200 as fileid_11\n",
      "Saved: speaker 06967 as fileid_12\n",
      "Saved: speaker 02964 as fileid_13\n",
      "Saved: speaker 05299 as fileid_14\n",
      "Saved: speaker 11329 as fileid_15\n",
      "Saved: speaker 03259 as fileid_16\n",
      "Saved: speaker 02584 as fileid_17\n",
      "Saved: speaker 00727 as fileid_18\n",
      "Saved: speaker 10008 as fileid_19\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import torchaudio\n",
    "\n",
    "def parse_reader_id(filename):\n",
    "    match = re.search(r\"reader_(\\d+)_\", filename)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def organize_and_resample_clips(src_dir, dest_dir, num_speakers=10, clips_per_speaker=10, seed=42, target_sr=16000):\n",
    "    random.seed(seed)\n",
    "    src_dir = Path(src_dir)\n",
    "    dest_dir = Path(dest_dir)\n",
    "\n",
    "    original_clean_wav_dir = dest_dir / \"original_clean_wav\"\n",
    "    original_clean_train_dir = dest_dir / \"original_clean_train\"\n",
    "    clean_wav_dir = dest_dir / \"clean_wav\"\n",
    "    clean_train_dir = dest_dir / \"clean_train\"\n",
    "\n",
    "    for d in [original_clean_wav_dir, original_clean_train_dir, clean_wav_dir, clean_train_dir]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    speaker_to_files = defaultdict(list)\n",
    "    for file in src_dir.glob(\"*.wav\"):\n",
    "        reader_id = parse_reader_id(file.name)\n",
    "        if reader_id:\n",
    "            speaker_to_files[reader_id].append(file)\n",
    "\n",
    "    eligible_speakers = [s for s, files in speaker_to_files.items() if len(files) >= clips_per_speaker]\n",
    "    selected_speakers = random.sample(eligible_speakers, min(num_speakers, len(eligible_speakers)))\n",
    "\n",
    "    for idx, reader_id in enumerate(selected_speakers):\n",
    "        files = random.sample(speaker_to_files[reader_id], clips_per_speaker)\n",
    "        main_clip = files[0]\n",
    "        support_clips = files[1:]\n",
    "        file_id = f\"fileid_{idx}\"\n",
    "\n",
    "        # Original\n",
    "        shutil.copy(main_clip, original_clean_wav_dir / main_clip.name)\n",
    "        orig_train_dir = original_clean_train_dir / file_id\n",
    "        orig_train_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for clip in support_clips:\n",
    "            shutil.copy(clip, orig_train_dir / clip.name)\n",
    "\n",
    "        # Resampled\n",
    "        waveform, sr = torchaudio.load(main_clip)\n",
    "        if sr != target_sr:\n",
    "            waveform = torchaudio.functional.resample(waveform, sr, target_sr)\n",
    "        torchaudio.save(clean_wav_dir / f\"{main_clip.stem}_{file_id}.wav\", waveform, target_sr,encoding=\"PCM_F\")\n",
    "\n",
    "        resampled_dir = clean_train_dir / file_id\n",
    "        resampled_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for clip in support_clips:\n",
    "            waveform, sr = torchaudio.load(clip)\n",
    "            if sr != target_sr:\n",
    "                waveform = torchaudio.functional.resample(waveform, sr, target_sr)\n",
    "            torchaudio.save(resampled_dir / clip.name, waveform, target_sr,encoding=\"PCM_F\")\n",
    "\n",
    "        print(f\"Saved: speaker {reader_id} as {file_id}\")\n",
    "\n",
    "# Example:\n",
    "src_dir=\"/data/ephraim/datasets/DNS-Challenge_old/datasets/clean\"\n",
    "dest_dir=\"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net3_6_SNR5/\"\n",
    "organize_and_resample_clips(src_dir, dest_dir, num_speakers=20, clips_per_speaker=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def copy_directory(src_dir, dest_dir, overwrite=False):\n",
    "    \"\"\"\n",
    "    Copy a directory and all its contents from src_dir to dest_dir.\n",
    "\n",
    "    Parameters:\n",
    "    - src_dir (str or Path): Source directory path\n",
    "    - dest_dir (str or Path): Destination directory path\n",
    "    - overwrite (bool): If True, will overwrite the destination if it exists\n",
    "    \"\"\"\n",
    "    src_dir = Path(src_dir)\n",
    "    dest_dir = Path(dest_dir)\n",
    "\n",
    "    if not src_dir.exists():\n",
    "        raise FileNotFoundError(f\"Source directory '{src_dir}' does not exist.\")\n",
    "\n",
    "    if dest_dir.exists():\n",
    "        if overwrite:\n",
    "            shutil.rmtree(dest_dir)\n",
    "        else:\n",
    "            raise FileExistsError(f\"Destination '{dest_dir}' already exists. Use overwrite=True to replace it.\")\n",
    "\n",
    "    shutil.copytree(src_dir, dest_dir)\n",
    "    print(f\"Copied '{src_dir}' → '{dest_dir}'\")\n",
    "\n",
    "# Example usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_directory(\"/data/ephraim/datasets/known_noise/undiff_exps3/exp_libr20/\", \"/data/ephraim/datasets/known_noise/undiff_exps3/exp_libr16/\", overwrite=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def insert_snr_tag_in_filenames(directory, tag=\"snr5\"):\n",
    "    \"\"\"\n",
    "    Insert '_snr5' before '_fileid_' in all .wav filenames within `directory`.\n",
    "    \"\"\"\n",
    "    directory = Path(directory)\n",
    "    for wav_file in directory.glob(\"*.wav\"):\n",
    "        old_name = wav_file.name\n",
    "        if \"_fileid_\" in old_name:\n",
    "            parts = old_name.split(\"_fileid_\")\n",
    "            new_name = f\"{parts[0]}_{tag}_fileid_{parts[1]}\"\n",
    "            new_path = wav_file.with_name(new_name)\n",
    "            os.rename(wav_file, new_path)\n",
    "            print(f\"Renamed: {old_name} → {new_name}\")\n",
    "        else:\n",
    "            print(f\"Skipped (no _fileid_): {old_name}\")\n",
    "\n",
    "# Example usage:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bbc dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#bbc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, csv, shutil, torch, torchaudio, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# CONFIG ------------------------------------------------------------------\n",
    "TARGET_SR  = 16_000          # Hz\n",
    "TARGET_SNR = 5.0             # dB\n",
    "SKIP_SEC   = 2               # do not use first 2 s of noise\n",
    "SEED       = 123\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# UTILITIES ---------------------------------------------------------------\n",
    "def resample_mono(w, old_sr, new_sr=TARGET_SR):\n",
    "    w = w[:1]                                   # first channel\n",
    "    return torchaudio.functional.resample(w, old_sr, new_sr) if old_sr != new_sr else w\n",
    "\n",
    "def scale_to_snr(clean, noise, snr_db):\n",
    "    return noise * torch.sqrt(torch.mean(clean**2) /\n",
    "                              (torch.mean(noise**2) * 10**(snr_db/10)))\n",
    "\n",
    "def scan_noise(root):\n",
    "    \"\"\"Return shuffled list of all noise paths.\"\"\"\n",
    "    paths = list(Path(root).rglob(\"*.wav\"))\n",
    "    random.shuffle(paths)\n",
    "    return paths\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# MAIN --------------------------------------------------------------------\n",
    "def mix_clean_with_long_noise(dest_dir, noise_root, snr_db=TARGET_SNR):\n",
    "    dest = Path(dest_dir)\n",
    "    clean_dir = dest / \"clean_wav\"\n",
    "    out = {k: dest/k for k in (\"noisy_wav\",\"noises\",\"original_noises\")}\n",
    "    for d in out.values():\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    mapping_rows = []\n",
    "    skip_frames  = SKIP_SEC * TARGET_SR\n",
    "    noise_pool   = scan_noise(noise_root)\n",
    "    noise_idx    = 0                            # pointer into shuffled pool\n",
    "\n",
    "    for clean_file in sorted(clean_dir.glob(\"*.wav\")):\n",
    "        # -------- load clean (mono 16 k) ----------------------------------\n",
    "        c, sr = torchaudio.load(clean_file)\n",
    "        c = resample_mono(c, sr)\n",
    "        L = c.shape[-1]\n",
    "\n",
    "        # -------- find a unique noise WAV long enough ---------------------\n",
    "        while noise_idx < len(noise_pool):\n",
    "            n_path = noise_pool[noise_idx]; noise_idx += 1\n",
    "            n_raw, sr_n = torchaudio.load(n_path)\n",
    "            n_mono      = resample_mono(n_raw, sr_n)[:, skip_frames:]\n",
    "            if n_mono.shape[-1] >= L:              # usable!\n",
    "                break\n",
    "        else:\n",
    "            raise RuntimeError(\"Ran out of long noise files.\")\n",
    "\n",
    "        start = random.randint(0, n_mono.shape[-1] - L)\n",
    "        seg   = n_mono[:, start:start+L]\n",
    "        seg   = scale_to_snr(c, seg, snr_db)\n",
    "        noisy = c + seg\n",
    "\n",
    "        # -------- save outputs -------------------------------------------\n",
    "        shutil.copy(n_path, out[\"original_noises\"]/clean_file.name)\n",
    "        torchaudio.save(out[\"noises\"]/clean_file.name, seg,   TARGET_SR)\n",
    "        torchaudio.save(out[\"noisy_wav\"]/clean_file.name, noisy, TARGET_SR)\n",
    "\n",
    "        mapping_rows.append([\n",
    "            str(clean_file),\n",
    "            str(out[\"noisy_wav\"]/clean_file.name),\n",
    "            str(out[\"noises\"]/clean_file.name),\n",
    "            str(n_path),\n",
    "            start + skip_frames,\n",
    "            start + L - 1 + skip_frames,\n",
    "            snr_db\n",
    "        ])\n",
    "\n",
    "        print(f\"{clean_file.name:<25}  ←  {n_path.name}  |  SNR={snr_db} dB\")\n",
    "\n",
    "    # -------- write mapping CSV ------------------------------------------\n",
    "    map_csv = dest / \"noise_mapping.csv\"\n",
    "    with open(map_csv, \"w\", newline=\"\") as f:\n",
    "        csv.writer(f).writerows([[\"clean\",\"noisy\",\"noise_seg\",\n",
    "                                  \"noise_src\",\"start\",\"end\",\"snr_db\"],\n",
    "                                 *mapping_rows])\n",
    "    print(f\"\\nMapping saved to {map_csv}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Example call\n",
    "# ------------------------------------------------------------------\n",
    "# mix_clean_with_long_noise(\n",
    "#     dest_dir   = \"/path/to/dest\",\n",
    "#     noise_root = \"/path/to/BBC_noise_dataset\",\n",
    "#     snr_db     = 5.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_00334_chp_0040_reader_11377_3_fileid_2.wav  ←  NHU05104248.wav  |  SNR=5.0 dB\n",
      "book_00375_chp_0010_reader_02584_13_fileid_17.wav  ←  07044002.wav  |  SNR=5.0 dB\n",
      "book_01265_chp_0062_reader_02964_24_fileid_13.wav  ←  NHU05086083.wav  |  SNR=5.0 dB\n",
      "book_01296_chp_0015_reader_00727_63_fileid_18.wav  ←  NHU05084027.wav  |  SNR=5.0 dB\n",
      "book_01436_chp_0016_reader_04278_31_fileid_9.wav  ←  07015100.wav  |  SNR=5.0 dB\n",
      "book_01652_chp_0035_reader_09440_9_fileid_1.wav  ←  07022168.wav  |  SNR=5.0 dB\n",
      "book_02132_chp_0098_reader_00123_6_fileid_7.wav  ←  NHU05101064.wav  |  SNR=5.0 dB\n",
      "book_03136_chp_0008_reader_10008_3_fileid_19.wav  ←  NHU05070103.wav  |  SNR=5.0 dB\n",
      "book_03171_chp_0011_reader_04433_25_fileid_6.wav  ←  NHU05071088.wav  |  SNR=5.0 dB\n",
      "book_03465_chp_0008_reader_06475_9_fileid_5.wav  ←  NHU05011211.wav  |  SNR=5.0 dB\n",
      "book_03855_chp_0007_reader_11207_2_fileid_4.wav  ←  07015058.wav  |  SNR=5.0 dB\n",
      "book_06051_chp_0008_reader_11329_7_fileid_15.wav  ←  07064025.wav  |  SNR=5.0 dB\n",
      "book_07834_chp_0006_reader_03259_0_fileid_16.wav  ←  NHU05093027.wav  |  SNR=5.0 dB\n",
      "book_07962_chp_0016_reader_06967_43_fileid_12.wav  ←  07072005.wav  |  SNR=5.0 dB\n",
      "book_08563_chp_0006_reader_05299_4_fileid_14.wav  ←  07044101.wav  |  SNR=5.0 dB\n",
      "book_09293_chp_0013_reader_03714_35_fileid_0.wav  ←  NHU05015020.wav  |  SNR=5.0 dB\n",
      "book_09902_chp_0050_reader_07893_9_fileid_10.wav  ←  07022138.wav  |  SNR=5.0 dB\n",
      "book_11020_chp_0008_reader_06271_24_fileid_8.wav  ←  NHU05086161.wav  |  SNR=5.0 dB\n",
      "book_11069_chp_0022_reader_08200_15_fileid_11.wav  ←  NHU05097246.wav  |  SNR=5.0 dB\n",
      "book_11099_chp_0020_reader_04199_55_fileid_3.wav  ←  NHU05093021.wav  |  SNR=5.0 dB\n",
      "\n",
      "Mapping saved to /data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net3_6_SNR5/noise_mapping.csv\n"
     ]
    }
   ],
   "source": [
    "mix_clean_with_long_noise(\n",
    "    dest_dir  = \"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net3_6_SNR5\",\n",
    "    noise_root = \"/data/ephraim/datasets/known_noise/bbc-noises/bbc20/\",\n",
    "    snr_db= 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed: book_00334_chp_0040_reader_11377_3_fileid_2.wav → book_00334_chp_0040_reader_11377_3_snr5_fileid_2.wav\n",
      "Renamed: book_00375_chp_0010_reader_02584_13_fileid_17.wav → book_00375_chp_0010_reader_02584_13_snr5_fileid_17.wav\n",
      "Renamed: book_01265_chp_0062_reader_02964_24_fileid_13.wav → book_01265_chp_0062_reader_02964_24_snr5_fileid_13.wav\n",
      "Renamed: book_01296_chp_0015_reader_00727_63_fileid_18.wav → book_01296_chp_0015_reader_00727_63_snr5_fileid_18.wav\n",
      "Renamed: book_01436_chp_0016_reader_04278_31_fileid_9.wav → book_01436_chp_0016_reader_04278_31_snr5_fileid_9.wav\n",
      "Renamed: book_01652_chp_0035_reader_09440_9_fileid_1.wav → book_01652_chp_0035_reader_09440_9_snr5_fileid_1.wav\n",
      "Renamed: book_02132_chp_0098_reader_00123_6_fileid_7.wav → book_02132_chp_0098_reader_00123_6_snr5_fileid_7.wav\n",
      "Renamed: book_03136_chp_0008_reader_10008_3_fileid_19.wav → book_03136_chp_0008_reader_10008_3_snr5_fileid_19.wav\n",
      "Renamed: book_03171_chp_0011_reader_04433_25_fileid_6.wav → book_03171_chp_0011_reader_04433_25_snr5_fileid_6.wav\n",
      "Renamed: book_03465_chp_0008_reader_06475_9_fileid_5.wav → book_03465_chp_0008_reader_06475_9_snr5_fileid_5.wav\n",
      "Renamed: book_03855_chp_0007_reader_11207_2_fileid_4.wav → book_03855_chp_0007_reader_11207_2_snr5_fileid_4.wav\n",
      "Renamed: book_06051_chp_0008_reader_11329_7_fileid_15.wav → book_06051_chp_0008_reader_11329_7_snr5_fileid_15.wav\n",
      "Renamed: book_07834_chp_0006_reader_03259_0_fileid_16.wav → book_07834_chp_0006_reader_03259_0_snr5_fileid_16.wav\n",
      "Renamed: book_07962_chp_0016_reader_06967_43_fileid_12.wav → book_07962_chp_0016_reader_06967_43_snr5_fileid_12.wav\n",
      "Renamed: book_08563_chp_0006_reader_05299_4_fileid_14.wav → book_08563_chp_0006_reader_05299_4_snr5_fileid_14.wav\n",
      "Renamed: book_09293_chp_0013_reader_03714_35_fileid_0.wav → book_09293_chp_0013_reader_03714_35_snr5_fileid_0.wav\n",
      "Renamed: book_09902_chp_0050_reader_07893_9_fileid_10.wav → book_09902_chp_0050_reader_07893_9_snr5_fileid_10.wav\n",
      "Renamed: book_11020_chp_0008_reader_06271_24_fileid_8.wav → book_11020_chp_0008_reader_06271_24_snr5_fileid_8.wav\n",
      "Renamed: book_11069_chp_0022_reader_08200_15_fileid_11.wav → book_11069_chp_0022_reader_08200_15_snr5_fileid_11.wav\n",
      "Renamed: book_11099_chp_0020_reader_04199_55_fileid_3.wav → book_11099_chp_0020_reader_04199_55_snr5_fileid_3.wav\n"
     ]
    }
   ],
   "source": [
    "insert_snr_tag_in_filenames(\"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net3_6_SNR5/noisy_wav\", tag=\"snr5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_directory(\"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net3_6_SNR5/\", \"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net3_6_SNR-5/\", overwrite=False)\n",
    "copy_directory(\"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net3_6_SNR5/\", \"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net3_6_SNR0/\", overwrite=False)\n",
    "copy_directory(\"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net3_6_SNR5/\", \"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net3_6_SNR10/\", overwrite=False)\n",
    "copy_directory(\"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net3_6_SNR5/\", \"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net30_SNR5/\", overwrite=False)\n",
    "copy_directory(\"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net3_6_SNR5/\", \"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net40_SNR5/\", overwrite=False)\n",
    "copy_directory(\"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net3_6_SNR5/\", \"/data/ephraim/datasets/known_noise/undiff_exps3/exp_libr20_p_net2_6_SNR5/\", overwrite=False)\n",
    "copy_directory(\"/data/ephraim/datasets/known_noise/undiff_exps3/exp_librBBC20_net3_6_SNR5/\", \"/data/ephraim/datasets/known_noise/undiff_exps3/exp_libr20_p_net3_6_SNR5/\", overwrite=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
